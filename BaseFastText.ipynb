{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8w2-0gZ-XeHO"
   },
   "outputs": [],
   "source": [
    "### This File is made to work on google colab, but can work with modifications locally\n",
    "### Import Pytorch and other relevant packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "### Import MNIST dataset \n",
    "from torchvision.datasets import MNIST\n",
    "### Load Numpy and Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "from DataProcessor import DataInstance, DataProcesser\n",
    "\n",
    "import sklearn.metrics as mec\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, adjusted_rand_score\n",
    "\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import math\n",
    "import struct\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dprm-LUX6AJ"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSgfryaDX8kW"
   },
   "outputs": [],
   "source": [
    "ProcessedSet = DataProcesser.load('./processed-fasttext-raw.bin') # fasttext processed data\n",
    "seed = 0\n",
    "TrainingSplit = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtfQGwt5atcg"
   },
   "outputs": [],
   "source": [
    "def NavieSampler(Processor):\n",
    "  ros = RandomOverSampler(random_state=seed)\n",
    "\n",
    "  x = list(map(lambda x: [x], Processor.instances))\n",
    "  y = Processor.labels()\n",
    "\n",
    "  x, y = ros.fit_resample(x, y)\n",
    "\n",
    "  return DataProcesser.FromInstances(list(map(lambda v: v[0], x)))\n",
    "\n",
    "\n",
    "def Splitter(Processor, split = .2):\n",
    "  # Processor contains all data\n",
    "  # Split is the split ration\n",
    "\n",
    "  data = Processor.instances\n",
    "  np.random.seed(seed)\n",
    "  splitIndex = np.random.choice(len(data), len(data), replace=False).astype(int)\n",
    "\n",
    "\n",
    "  split = round((1.0-split)*len(data))\n",
    "  \n",
    "  set1 = np.array(data)[splitIndex[0:split]]\n",
    "  set2 = np.array(data)[splitIndex[split:]]\n",
    "\n",
    "  return DataProcesser.FromInstances(set1),  DataProcesser.FromInstances(set2)\n",
    "\n",
    "\n",
    "Train, Valid = Splitter(ProcessedSet, TrainingSplit)\n",
    "\n",
    "\n",
    "dimX = Train.preds()[0].shape[0]\n",
    "dimY = Train.labels()[0].shape[0]\n",
    "\n",
    "\n",
    "Train = NavieSampler(Train)\n",
    "Train.cuda()\n",
    "\n",
    "TrainingSet = TensorDataset(Train.preds(), Train.labels())\n",
    "\n",
    "print(len(ProcessedSet.instances))\n",
    "print(len(Train.instances))\n",
    "print(len(Valid.instances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3J9i-y7ZEmN"
   },
   "outputs": [],
   "source": [
    "### BaseLine class\n",
    "class BaseLine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseLine, self).__init__()\n",
    "        ### Encoder layers\n",
    "        self.out = nn.Linear(dimX, dimY)\n",
    "        self.logit = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### Autoencoder returns the reconstruction \n",
    "        ### and latent representation\n",
    "        x = self.out(x)\n",
    "        x = self.logit(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def evaluate(Processer, model):\n",
    "  with torch.no_grad():\n",
    "    res = model(Processer.preds())\n",
    "  \n",
    "  def PRound(t): \n",
    "    t = t.numpy()\n",
    "    return (t.T/t.max(axis=1)).T.round()\n",
    "\n",
    "  Processer.cpu()\n",
    "  res = res.cpu()\n",
    "  true = Processer.labels()\n",
    "  rounded = PRound(res.squeeze(1))\n",
    "\n",
    "  return mec.classification_report(true, rounded), (true, rounded)\n",
    "\n",
    "\n",
    "def plotTrainingSession(loss_train, loss_valid):\n",
    "  plt.figure(figsize = (10,5))\n",
    "  plt.plot(loss_train, label='Training loss')\n",
    "  plt.plot(loss_valid, label='Validation loss')\n",
    "  plt.legend(loc=\"upper right\")\n",
    "  plt.ylabel('BCE Batch Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.show()\n",
    "\n",
    "def ConfusionPlot(Processed, model):\n",
    "  Processed.cuda()\n",
    "  _, (labels, rounded) = evaluate(Processed , model)\n",
    "\n",
    "  Map = np.zeros((18,18))\n",
    "  Processed.cpu()\n",
    "\n",
    "  for x, y in zip(rounded, labels):\n",
    "    label = np.where(y==1.0)[0][0]\n",
    "    Map[label] += x\n",
    "    Map[label] = Map[label]\n",
    "\n",
    "  for i, lane in enumerate(Map):\n",
    "    Map[i] = Map[i]/sum(lane)\n",
    "\n",
    "\n",
    "  plt.figure(figsize = (20,20))\n",
    "  classes = range(18)\n",
    "  plt.imshow(Map.T, interpolation='nearest')\n",
    "  plt.clim(0.0,1.0)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blANsF0JZFuS"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed) # set fixed random seed for reproducibility\n",
    "\n",
    "model = BaseLine().cuda()\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.BCELoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainLossEpochs = []\n",
    "validLossEpochs = []\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TrainingSet,\n",
    "    batch_size=20, shuffle=True)\n",
    "\n",
    "Valid.cuda()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        #loss = loss_function(outputs.squeeze(1).float(), labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "   \n",
    "    print('====> Epoch: {} Total Loss: {:.4f} Average Batch Loss {:.4f}\\r'.format(\n",
    "          epoch, running_loss, running_loss/batch_idx))\n",
    "    trainLossEpochs.append(running_loss/batch_idx)\n",
    "    with torch.no_grad():\n",
    "      out = model(Valid.preds())\n",
    "      validLoss = loss_function(out, Valid.labels().float()).item()\n",
    "      validLossEpochs.append(validLoss)\n",
    "      print('===> Validation Loss {}'.format(validLoss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ka9z5lLWzwG"
   },
   "outputs": [],
   "source": [
    "Train.cuda()\n",
    "Valid.cuda()\n",
    "ProcessedSet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSo9ZdbWWGTv"
   },
   "outputs": [],
   "source": [
    "print(\"Loss plot\")\n",
    "plotTrainingSession(trainLossEpochs, validLossEpochs)\n",
    "print(\"Training\")\n",
    "evalText, matrix = evaluate(Train, model)\n",
    "print(evalText)\n",
    "print(\"--\"*20)\n",
    "print(\"Validation\")\n",
    "evalText, matrix = evaluate(Valid, model)\n",
    "print(evalText)\n",
    "print(\"--\"*20)\n",
    "print(\"Over All\")\n",
    "evalText, matrix = evaluate(ProcessedSet, model)\n",
    "print(evalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRjiItJXqP5K"
   },
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "ConfusionPlot(Train, model)\n",
    "print(\"--\"*20)\n",
    "print(\"Validation\")\n",
    "ConfusionPlot(Valid, model)\n",
    "print(\"--\"*20)\n",
    "print(\"Over All\")\n",
    "ConfusionPlot(ProcessedSet, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDlW-G0SU0TW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BaseFastText.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
